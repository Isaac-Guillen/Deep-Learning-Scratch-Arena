{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Regularization - MXNet (From scratch).ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "1X1zUuZdP5qp",
        "colab_type": "code",
        "outputId": "d563a333-b94a-409a-ea96-89709df498a6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        }
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: mxnet-cu100 in /usr/local/lib/python3.6/dist-packages (1.4.1)\n",
            "Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (0.8.4)\n",
            "Requirement already satisfied: requests>=2.20.0 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (2.21.0)\n",
            "Requirement already satisfied: numpy<1.15.0,>=1.8.2 in /usr/local/lib/python3.6/dist-packages (from mxnet-cu100) (1.14.6)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2019.3.9)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.20.0->mxnet-cu100) (2.8)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Q-6x9JFQfJA",
        "colab_type": "text"
      },
      "source": [
        "#MXNet (From Scratch)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yp7iLrxpQeX3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import mxnet as mx\n",
        "from mxnet import nd, autograd, gluon\n",
        "\n",
        "data_ctx = mx.cpu()\n",
        "model_ctx = mx.gpu()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aM8vNhRqQxd2",
        "colab_type": "text"
      },
      "source": [
        "##Getting dataset and builing data loader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p3MUlf5HQeZY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mnist = mx.test_utils.get_mnist()\n",
        "num_examples = 60000\n",
        "batch_size = 64\n",
        "\n",
        "train_data = mx.gluon.data.DataLoader(\n",
        "    mx.gluon.data.ArrayDataset(mnist[\"train_data\"][:num_examples],\n",
        "                               mnist[\"train_label\"][:num_examples].astype('float32')),\n",
        "                               batch_size, shuffle=True)\n",
        "test_data = mx.gluon.data.DataLoader(\n",
        "    mx.gluon.data.ArrayDataset(mnist[\"test_data\"][:num_examples],\n",
        "                               mnist[\"test_label\"][:num_examples].astype('float32')),\n",
        "                               batch_size, shuffle=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AUcPs5hQTmx2",
        "colab_type": "text"
      },
      "source": [
        "##Building the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JU6i-pGPQedi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "weight = nd.random.normal(shape=(784,10), ctx = model_ctx)\n",
        "bias = nd.random.normal(shape=10, ctx = model_ctx)\n",
        "\n",
        "params = [weight, bias]\n",
        "\n",
        "for param in params:\n",
        "    param.attach_grad()\n",
        "\n",
        "def model(inputs):\n",
        "    return nd.softmax(nd.dot(inputs, weight) + bias, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m2gk-c_KTssi",
        "colab_type": "text"
      },
      "source": [
        "##Defining the objective function and optimizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c8KneO0MQee7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def categoricalcrossentropy(predictions, labels):\n",
        "    return -nd.sum(labels * nd.log(predictions))\n",
        "\n",
        "def sgd(params, lr):\n",
        "    for param in params:\n",
        "        param[:] = param - lr * param.grad"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LosCXfNZU11a",
        "colab_type": "text"
      },
      "source": [
        "##Defining regularization function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WrPQzJifQehA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def l1(params, lamda):\n",
        "    penalty = nd.zeros(shape=1).as_in_context(model_ctx)\n",
        "    for param in params:\n",
        "        penalty = penalty + nd.sum(nd.abs(param))\n",
        "    return lamda * penalty    \n",
        "\n",
        "def l2(params, lamda):\n",
        "    penalty = nd.zeros(shape=1).as_in_context(model_ctx)\n",
        "    for param in params:\n",
        "        penalty = penalty + nd.sum(param ** 2)\n",
        "    return lamda * penalty"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EeEkwT6qWPTX",
        "colab_type": "text"
      },
      "source": [
        "##Defining accuracy function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ff2oB_yFWR9O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def accuracy(predictions, labels):\n",
        "    return nd.mean(predictions.argmax(1) == labels.argmax(1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_wZ0g5VwVF-x",
        "colab_type": "text"
      },
      "source": [
        "##Training the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yn3p264lQej3",
        "colab_type": "code",
        "outputId": "700813e2-4306-4154-f21e-830883b020a2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 353
        }
      },
      "source": [
        "epochs = 20\n",
        "num_batches = 60000/batch_size\n",
        "learning_rate = .01\n",
        "lamda = 0.01\n",
        "losses = []\n",
        "accs = []\n",
        "\n",
        "for epoch in range(epochs):\n",
        "    cumulative_loss = 0\n",
        "    cumulative_acc = 0\n",
        "    for features, labels in train_data:\n",
        "        features = features.as_in_context(model_ctx).reshape((-1, 784))\n",
        "        labels = labels.as_in_context(model_ctx).one_hot(10)\n",
        "        with autograd.record():\n",
        "            output = model(features)\n",
        "            loss = categoricalcrossentropy(output, labels) + l2(params, lamda)\n",
        "        loss.backward()\n",
        "        sgd(params, learning_rate)\n",
        "        cumulative_loss += loss\n",
        "        cumulative_acc += accuracy(output, labels)\n",
        "    print(f'Epoch: {epoch} Loss: {cumulative_loss.asscalar()/num_batches} Accuracy: {cumulative_acc.asscalar()/num_batches}')\n",
        "    losses.append(cumulative_loss.asscalar()/num_batches)\n",
        "    accs.append(cumulative_acc.asscalar()/num_batches)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch: 0 Loss: 120.46835833333333 Accuracy: 0.8213666666666667\n",
            "Epoch: 1 Loss: 67.48980833333333 Accuracy: 0.8883333333333333\n",
            "Epoch: 2 Loss: 49.50472083333333 Accuracy: 0.9019333333333334\n",
            "Epoch: 3 Loss: 39.076366666666665 Accuracy: 0.9101333333333333\n",
            "Epoch: 4 Loss: 32.68465416666667 Accuracy: 0.9134\n",
            "Epoch: 5 Loss: 28.76230625 Accuracy: 0.9149833333333334\n",
            "Epoch: 6 Loss: 26.101997916666665 Accuracy: 0.9155666666666666\n",
            "Epoch: 7 Loss: 24.256166666666665 Accuracy: 0.91755\n",
            "Epoch: 8 Loss: 23.204591666666666 Accuracy: 0.91745\n",
            "Epoch: 9 Loss: 22.444966666666666 Accuracy: 0.9168166666666666\n",
            "Epoch: 10 Loss: 21.89431875 Accuracy: 0.9178833333333334\n",
            "Epoch: 11 Loss: 21.649058333333333 Accuracy: 0.9174\n",
            "Epoch: 12 Loss: 21.354272916666666 Accuracy: 0.9171666666666667\n",
            "Epoch: 13 Loss: 21.328358333333334 Accuracy: 0.91585\n",
            "Epoch: 14 Loss: 21.146654166666668 Accuracy: 0.9164666666666667\n",
            "Epoch: 15 Loss: 21.123816666666666 Accuracy: 0.9173\n",
            "Epoch: 16 Loss: 20.968764583333332 Accuracy: 0.917\n",
            "Epoch: 17 Loss: 20.95968125 Accuracy: 0.9190166666666667\n",
            "Epoch: 18 Loss: 20.973220833333333 Accuracy: 0.91765\n",
            "Epoch: 19 Loss: 20.85386875 Accuracy: 0.91845\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-nH5xCdcKPq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "plt.plot(losses)\n",
        "plt.title('Training Loss')\n",
        "plt.show()\n",
        "plt.plot(accs)\n",
        "plt.title('Training Accuracy')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eRkTd9d9Qecj",
        "colab_type": "code",
        "outputId": "b1b29ec6-d116-4504-a995-ceb14e6e5eaf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "acc = 0.0\n",
        "batches = 0\n",
        "for features, labels in test_data:\n",
        "    features = features.as_in_context(model_ctx).reshape((-1, 784))\n",
        "    labels = labels.as_in_context(model_ctx).one_hot(10)\n",
        "    predictions = model(features)\n",
        "    acc += accuracy(predictions, labels)\n",
        "    batches += 1\n",
        "print(f'Test Accuracy: {acc.asscalar()/batches}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Test Accuracy: 0.9193869426751592\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC-InETCYWty",
        "colab_type": "text"
      },
      "source": [
        "### Even by training out model for full 20 epochs we still managed to force it not to overfit on the training data. "
      ]
    }
  ]
}